alias: null
batch_size: 32
drop_last_loader: false
dropout: 0.5
early_stop_patience_steps: -1
exclude_insample_y: false
futr_exog_list: null
h: 1
hidden_size: 16
hist_exog_list: null
inference_windows_batch_size: 1024
input_size: 24
learning_rate: 0.001
loss: !!python/object:neuralforecast.losses.pytorch.GMM
  _backward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _backward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _buffers: {}
  _forward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_always_called: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _is_full_backward_hook: null
  _load_state_dict_post_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _load_state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _modules: {}
  _non_persistent_buffers_set: !!set {}
  _parameters:
    quantiles: !!python/object/apply:torch._utils._rebuild_parameter
    - !!python/object/apply:torch._utils._rebuild_tensor_v2
      - !!python/object/apply:torch.storage._load_from_bytes
        - !!binary |
          gAKKCmz8nEb5IGqoUBkugAJN6QMugAJ9cQAoWBAAAABwcm90b2NvbF92ZXJzaW9ucQFN6QNYDQAA
          AGxpdHRsZV9lbmRpYW5xAohYCgAAAHR5cGVfc2l6ZXNxA31xBChYBQAAAHNob3J0cQVLAlgDAAAA
          aW50cQZLBFgEAAAAbG9uZ3EHSwR1dS6AAihYBwAAAHN0b3JhZ2VxAGN0b3JjaApGbG9hdFN0b3Jh
          Z2UKcQFYDQAAADIxMjQ5MDM5OTMyODBxAlgDAAAAY3B1cQNLBU50cQRRLoACXXEAWA0AAAAyMTI0
          OTAzOTkzMjgwcQFhLgUAAAAAAAAAAAAAP83MTD3NzMw9ZmZmPzMzcz8=
      - 0
      - !!python/tuple
        - 5
      - !!python/tuple
        - 1
      - false
      - !!python/object/apply:collections.OrderedDict
        - []
    - false
    - !!python/object/apply:collections.OrderedDict
      - []
  _state_dict_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  batch_correlation: false
  horizon_correlation: false
  is_distribution_output: true
  num_samples: 1000
  output_names:
  - ''
  - -median
  - !!python/object/apply:numpy.core.multiarray.scalar
    - !!python/object/apply:numpy.dtype
      args:
      - U6
      - false
      - true
      state: !!python/tuple
      - 3
      - <
      - null
      - null
      - null
      - 24
      - 4
      - 8
    - !!binary |
      LQAAAGwAAABvAAAALQAAADkAAAAwAAAA
  - !!python/object/apply:numpy.core.multiarray.scalar
    - !!python/object/apply:numpy.dtype
      args:
      - U6
      - false
      - true
      state: !!python/tuple
      - 3
      - <
      - null
      - null
      - null
      - 24
      - 4
      - 8
    - !!binary |
      LQAAAGwAAABvAAAALQAAADgAAAAwAAAA
  - !!python/object/apply:numpy.core.multiarray.scalar
    - !!python/object/apply:numpy.dtype
      args:
      - U6
      - false
      - true
      state: !!python/tuple
      - 3
      - <
      - null
      - null
      - null
      - 24
      - 4
      - 8
    - !!binary |
      LQAAAGgAAABpAAAALQAAADgAAAAwAAAA
  - !!python/object/apply:numpy.core.multiarray.scalar
    - !!python/object/apply:numpy.dtype
      args:
      - U6
      - false
      - true
      state: !!python/tuple
      - 3
      - <
      - null
      - null
      - null
      - 24
      - 4
      - 8
    - !!binary |
      LQAAAGgAAABpAAAALQAAADkAAAAwAAAA
  - -mu-1
  - -std-1
  - -mu-2
  - -std-2
  - -mu-3
  - -std-3
  - -mu-4
  - -std-4
  - -mu-5
  - -std-5
  - -mu-6
  - -std-6
  - -mu-7
  - -std-7
  outputsize_multiplier: 14
  return_params: true
  training: true
lr_scheduler: null
lr_scheduler_kwargs: null
max_steps: 100
num_lr_decays: -1
num_workers_loader: 0
optimizer: null
optimizer_kwargs: null
random_seed: 1
scaler_type: standard
start_padding_enabled: false
stat_exog_list: null
step_size: 1
val_check_steps: 100
valid_batch_size: null
valid_loss: null
windows_batch_size: 1024
